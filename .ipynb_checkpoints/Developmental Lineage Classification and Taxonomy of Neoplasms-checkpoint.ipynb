{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Doublet Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-14T20:46:07.834Z"
    }
   },
   "outputs": [],
   "source": [
    "import dbm, string, re\n",
    "doubhash = dbm.open('doub', 'n')\n",
    "literalhash = dbm.open('literal', 'n')\n",
    "in_file = open('./K11946_Files/NEOCL.XML', \"r\")\n",
    "singular = re.compile('omas')\n",
    "england = re.compile('tumou?rs?')\n",
    "phrase = \"\"\n",
    "for line in in_file:\n",
    "    neoplasm_match = re.search(r'\\\"\\> ?(.+) ?\\<', line)\n",
    "    if neoplasm_match:\n",
    "        phrase = neoplasm_match.group(1)\n",
    "        phrase = singular.sub(\"oma\",phrase)\n",
    "        phrase = england.sub(\"tumor\",phrase)\n",
    "        literalhash[phrase] = \"\"\n",
    "    hoparray = phrase.split()\n",
    "    hoparray.append(\" \")\n",
    "    for i in range(len(hoparray)-1):\n",
    "        doublet = hoparray[i] + \" \" + hoparray[i + 1]\n",
    "        if doublet in doubhash:\n",
    "            continue\n",
    "        doubhash_match = re.search(r'[a-z]+ [a-z]+', doublet)\n",
    "        if doubhash_match:\n",
    "            doubhash[doublet] = \"\"\n",
    "doubhash.close()\n",
    "literalhash.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scanning the Literature for Candidate Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-14T20:50:34.502Z"
    }
   },
   "outputs": [],
   "source": [
    "import dbm, string, re\n",
    "doubhash = dbm.open('doub')\n",
    "literalhash = dbm.open('literal')\n",
    "newhash = {}\n",
    "in_file = open('./K11946_File/cancer_gene_titles.txt', 'r')\n",
    "line = \" \"\n",
    "count = 0\n",
    "singular = re.compile('omas')\n",
    "england = re.compile('tumou?rs?')\n",
    "for line in in_file:\n",
    "    bigline = line.rstrip(\" \\n\")\n",
    "    bigline = singular.sub(\"oma\", bigline)\n",
    "    bigline = england.sub(\"tumor\", bigline)\n",
    "    englishline = \"\"\n",
    "    hoparray = bigline.split()\n",
    "    hoparray.append(\" \")\n",
    "    for i in range(len(hoparray) - 1):\n",
    "        doublet = hoparray[i] + \" \" + hoparray[i + 1]\n",
    "        if doubhash.has_key(doublet):\n",
    "            if (englishline != \"\"):\n",
    "                englishline = englishline + \" \" + hoparray[i + 1]\n",
    "            else:\n",
    "                englishline = doublet\n",
    "        else:\n",
    "            if englishline != \"\":\n",
    "                englishline = englishline.strip()\n",
    "                englishline = re.sub(r'^the ', \"\", englishline)\n",
    "                englishline = re.sub(r'^in ', \"\", englishline)\n",
    "                englishline = re.sub(r'^of ', \"\", englishline)\n",
    "                englishline = re.sub(r'^and ', \"\", englishline)\n",
    "                englishline = re.sub(r'^with ', \"\", englishline)\n",
    "                englishline = re.sub(r'^from ', \"\", englishline)\n",
    "                englishline = re.sub(r'^ a', \"\", englishline)\n",
    "                englishline = re.sub(r' the$', \"\", englishline)\n",
    "                englishline = re.sub(r' in$', \"\", englishline)\n",
    "                englishline = re.sub(r' of$', \"\", englishline)\n",
    "                englishline = re.sub(r' and$', \"\", englishline)\n",
    "                englishline = re.sub(r' with$', \"\", englishline)\n",
    "                englishline = re.sub(r' from$', \"\", englishline)\n",
    "                englishline = re.sub(r' a$', \"\", englishline)\n",
    "                if literalhash.has_key(englishline):\n",
    "                    continue\n",
    "                if newhash.has_key(englishline):\n",
    "                    continue\n",
    "                phrase_match = re.search(r' [a-z]+ ', englishline)\n",
    "                if phrase_match:\n",
    "                    count = count + 1\n",
    "                    print str(count) + \" \" + englishline\n",
    "                    newhash[englishline] = \"\"\n",
    "doubhash.close()\n",
    "literalhash.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Terms to the Neoplasm Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-14T20:59:22.026Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, string\n",
    "vocab_in = open('./K11946_Files/NEOCL.XML', \"r\")\n",
    "doub_hash = {}\n",
    "for line in vocab_in:\n",
    "    code_match = re.search(r'C[0-9]{7}', line)\n",
    "    if not code_match:\n",
    "        continue\n",
    "    line_match = re.search(r'\\â€\\> ?(.+) ?\\<\\/', line)\n",
    "    if line_match:\n",
    "        phrase = line_match.group(1)\n",
    "        doub_hash[phrase] = \"\"\n",
    "vocab_in.close()\n",
    "candidate_file = open('./K11946_Files/neocl.lst', \"r\")\n",
    "out_file = open(\"new.out\", \"w\")\n",
    "for line in candidate_file:\n",
    "    line = re.sub(r'\\n',\"\", line)\n",
    "    if (line == \"\"):\n",
    "        continue\n",
    "    if line in doub_hash:\n",
    "        print line + \" already exists\"\n",
    "    else:\n",
    "        print(out_file, line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the Lineage of Every Neoplasm Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.parsers.expat\n",
    "import re\n",
    "parsefile = open('./K11946_Files/NEOCL.XML', \"r\")\n",
    "filestring = parsefile.read()\n",
    "lastname = \"\"\n",
    "code = \"\"\n",
    "count = 0\n",
    "text = \"\"\n",
    "def start_element(name, attrs):\n",
    "    global lastname\n",
    "    global code\n",
    "    if attrs.has_key(\"nci-code\"):\n",
    "        code = attrs[\"nci-code\"]\n",
    "    else:\n",
    "        lastname = name + \">\" + lastname\n",
    "def end_element(name):\n",
    "    global count\n",
    "    global code\n",
    "    global text\n",
    "    global lastname\n",
    "    if name == \"name\":\n",
    "        count = count + 1\n",
    "        print str(count) + \"|\" + text + \"|\" + code + \"|\" + lastname + \"\\n\"\n",
    "        text = \"\"\n",
    "    lastname = re.sub(name + r'>','', lastname)\n",
    "def char_data(data):\n",
    "    global text\n",
    "    text = repr(data)\n",
    "    textmatch = re.search(r'\\'(.+)\\'',text)\n",
    "    if textmatch:\n",
    "        text = textmatch.group(1)\n",
    "p = xml.parsers.expat.ParserCreate()\n",
    "p.StartElementHandler = start_element\n",
    "p.EndElementHandler = end_element\n",
    "p.CharacterDataHandler = char_data\n",
    "p.Parse(filestring)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
